{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "709e1ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from numpy import genfromtxt\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c9598f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bac4289d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'python' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vl/csb5xl656q31g25lr_cj83r00000gn/T/ipykernel_15718/1510789129.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'python' is not defined"
     ]
    }
   ],
   "source": [
    "python.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56eebae",
   "metadata": {},
   "source": [
    "load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45eeb179",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_vecs = genfromtxt('./data/user_vecs.csv', delimiter=',')\n",
    "item_vecs = genfromtxt('./data/item_vecs.csv', delimiter=',')\n",
    "item_embeddings = genfromtxt('./data/item_embeddings.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc502868",
   "metadata": {},
   "outputs": [],
   "source": [
    "vms = item_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423f5e48",
   "metadata": {},
   "source": [
    "load scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6af28225",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerUser = joblib.load('scalerUser.save')\n",
    "scalerItem = joblib.load('scalerItem.save')\n",
    "scalerTarget = joblib.load('scalerTarget.save')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3b25a5",
   "metadata": {},
   "source": [
    "Create dictionary for user_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71199d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dict = {}\n",
    "for i in range(len(user_vecs)):\n",
    "    user_dict[int(user_vecs[i][0])] = user_vecs[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ae77d9",
   "metadata": {},
   "source": [
    "load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7de13d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 15:44:19.116632: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('user_embedding_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a38197d",
   "metadata": {},
   "source": [
    "Generate user embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16ac118",
   "metadata": {},
   "outputs": [],
   "source": [
    "uid = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da67edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_vec = user_dict[uid].reshape(1,17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb0bb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_user_vec = scalerUser.transform(user_vec)\n",
    "vu = model.predict(scaled_user_vec[:,3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d380d588",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p = np.dot(vms, vu.T)\n",
    "y_pu = scalerTarget.inverse_transform(y_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c597fd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_index = np.argsort(-y_pu,axis=0).reshape(-1).tolist()  #negate to get largest rating first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe5efd3",
   "metadata": {},
   "source": [
    "Return the top 10 movie IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f1a184",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_vecs[sorted_index[:10],0].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ef4c30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(uid):\n",
    "    #compute user embedding\n",
    "    user_vec = user_dict[uid].reshape(1,17)\n",
    "    scaled_user_vec = scalerUser.transform(user_vec)\n",
    "    vu = model.predict(scaled_user_vec[:,3:])\n",
    "    \n",
    "    #compute dot product between user embedding and item embedding\n",
    "    y_p = np.dot(vms, vu.T)\n",
    "    y_pu = scalerTarget.inverse_transform(y_p)\n",
    "    \n",
    "    #Sort the result\n",
    "    sorted_index = np.argsort(-y_pu,axis=0).reshape(-1).tolist()  #negate to get largest rating first\n",
    "    \n",
    "    #return the top 10 movies\n",
    "    result = item_vecs[sorted_index[:10],0].astype(int)\n",
    "    \n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f526cd",
   "metadata": {},
   "source": [
    "deploy a fastapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f040c289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import uvicorn\n",
    "import numpy as np\n",
    "import json\n",
    "import nest_asyncio\n",
    "from enum import Enum\n",
    "from fastapi import FastAPI, UploadFile, File, HTTPException\n",
    "from fastapi.responses import StreamingResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c1e36f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f462e64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = FastAPI(title='Deploying a ML Model with FastAPI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "588c246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class User(BaseModel):\n",
    "    uid: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94ad9a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.get(\"/\")\n",
    "def home():\n",
    "    return \"Congratulations! Your API is working as expected. Now head over to http://localhost:8000/docs.\"\n",
    "\n",
    "@app.post(\"/predict\") \n",
    "def prediction(user: User):\n",
    "\n",
    "    payload = user.uid\n",
    "    print('payload is:',payload)\n",
    "    response = retrieve(payload).tolist()\n",
    "    print(\"response is:\", response)\n",
    "    \n",
    "    return {\"Recommended\":response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e07a245",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [79761]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:51462 - \"GET /docs HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:51462 - \"GET /openapi.json HTTP/1.1\" 200 OK\n",
      "payload is: 2\n",
      "response is: [150548, 114935, 105504, 80906, 115149, 81562, 27846, 122920, 104841, 96610]\n",
      "INFO:     127.0.0.1:51464 - \"POST /predict HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "# Allows the server to be run in this interactive environment\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Host depends on the setup you selected (docker or virtual env)\n",
    "host = \"0.0.0.0\" if os.getenv(\"DOCKER-SETUP\") else \"127.0.0.1\"\n",
    "\n",
    "# Spin up the server!    \n",
    "uvicorn.run(app, host=host, port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebea33b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7d71f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
