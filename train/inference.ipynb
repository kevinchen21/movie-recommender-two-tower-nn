{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "709e1ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "from numpy import genfromtxt\n",
    "import joblib\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56eebae",
   "metadata": {},
   "source": [
    "load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45eeb179",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_vecs = genfromtxt('./data/user_vecs.csv', delimiter=',')\n",
    "item_vecs = genfromtxt('./data/item_vecs.csv', delimiter=',')\n",
    "item_embeddings = genfromtxt('./data/item_embeddings.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc502868",
   "metadata": {},
   "outputs": [],
   "source": [
    "vms = item_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423f5e48",
   "metadata": {},
   "source": [
    "load scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6af28225",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerUser = joblib.load('scalerUser.save')\n",
    "scalerItem = joblib.load('scalerItem.save')\n",
    "scalerTarget = joblib.load('scalerTarget.save')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3b25a5",
   "metadata": {},
   "source": [
    "Create dictionary for user_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71199d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dict = {}\n",
    "for i in range(len(user_vecs)):\n",
    "    user_dict[int(user_vecs[i][0])] = user_vecs[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bd998dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.  , 22.  ,  4.  ,  3.95,  4.25,  0.  ,  0.  ,  4.  ,  4.12,\n",
       "        4.  ,  4.04,  0.  ,  3.  ,  4.  ,  0.  ,  3.88,  3.89])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_dict[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ae77d9",
   "metadata": {},
   "source": [
    "# load model for local testing\n",
    "\n",
    "Below, we also launch the user embedding model through docker container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7de13d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 17:29:20.894958: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# model = tf.keras.models.load_model('user_embedding_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a38197d",
   "metadata": {},
   "source": [
    "Generate user embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e16ac118",
   "metadata": {},
   "outputs": [],
   "source": [
    "uid = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5da67edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_vec = user_dict[uid].reshape(1,17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cb0bb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_user_vec = scalerUser.transform(user_vec)\n",
    "# vu = model.predict(scaled_user_vec[:,3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b35d3e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.dumps({\"instances\":scaled_user_vec[:,3:].tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a52312dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "headers = {\"content-type\": \"application/json\"}\n",
    "json_response = requests.post('http://localhost:8501/v1/models/user_embedding_model:predict', data=data, headers=headers)\n",
    "predictions = json.loads(json_response.text)['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ec32fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vu = np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65406354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.18111137,  0.19997938, -0.19132222,  0.09503911, -0.1601822 ,\n",
       "        -0.2680866 , -0.22200361,  0.05188859,  0.17674045,  0.09715266,\n",
       "        -0.2367947 ,  0.08048029, -0.04347603, -0.19147322,  0.1557557 ,\n",
       "         0.08408345,  0.41216803, -0.07486316, -0.10159047, -0.2744664 ,\n",
       "         0.13297854, -0.21316846, -0.01436659,  0.14857265, -0.134454  ,\n",
       "         0.16585004,  0.00517778, -0.03391952,  0.04715607,  0.08790212,\n",
       "        -0.29053682,  0.2670013 ]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d380d588",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p = np.dot(vms, vu.T)\n",
    "y_pu = scalerTarget.inverse_transform(y_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c597fd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_index = np.argsort(-y_pu,axis=0).reshape(-1).tolist()  #negate to get largest rating first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe5efd3",
   "metadata": {},
   "source": [
    "Return the top 10 movie IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f1a184",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_vecs[sorted_index[:10],0].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ef4c30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(uid):\n",
    "    #compute user embedding\n",
    "    user_vec = user_dict[uid].reshape(1,17)\n",
    "    scaled_user_vec = scalerUser.transform(user_vec)\n",
    "    vu = model.predict(scaled_user_vec[:,3:])\n",
    "    \n",
    "    #compute dot product between user embedding and item embedding\n",
    "    y_p = np.dot(vms, vu.T)\n",
    "    y_pu = scalerTarget.inverse_transform(y_p)\n",
    "    \n",
    "    #Sort the result\n",
    "    sorted_index = np.argsort(-y_pu,axis=0).reshape(-1).tolist()  #negate to get largest rating first\n",
    "    \n",
    "    #return the top 10 movies\n",
    "    result = item_vecs[sorted_index[:10],0].astype(int)\n",
    "    \n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f526cd",
   "metadata": {},
   "source": [
    "deploy a fastapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f040c289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import uvicorn\n",
    "import numpy as np\n",
    "import json\n",
    "import nest_asyncio\n",
    "from enum import Enum\n",
    "from fastapi import FastAPI, UploadFile, File, HTTPException\n",
    "from fastapi.responses import StreamingResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c1e36f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f462e64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = FastAPI(title='Deploying a ML Model with FastAPI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "588c246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class User(BaseModel):\n",
    "    uid: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94ad9a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.get(\"/\")\n",
    "def home():\n",
    "    return \"Congratulations! Your API is working as expected. Now head over to http://localhost:8000/docs.\"\n",
    "\n",
    "@app.post(\"/predict\") \n",
    "def prediction(user: User):\n",
    "\n",
    "    payload = user.uid\n",
    "    print('payload is:',payload)\n",
    "    response = retrieve(payload).tolist()\n",
    "    print(\"response is:\", response)\n",
    "    \n",
    "    return {\"Recommended\":response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e07a245",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [79761]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:51462 - \"GET /docs HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:51462 - \"GET /openapi.json HTTP/1.1\" 200 OK\n",
      "payload is: 2\n",
      "response is: [150548, 114935, 105504, 80906, 115149, 81562, 27846, 122920, 104841, 96610]\n",
      "INFO:     127.0.0.1:51464 - \"POST /predict HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "# Allows the server to be run in this interactive environment\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Host depends on the setup you selected (docker or virtual env)\n",
    "host = \"0.0.0.0\" if os.getenv(\"DOCKER-SETUP\") else \"127.0.0.1\"\n",
    "\n",
    "# Spin up the server!    \n",
    "uvicorn.run(app, host=host, port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebea33b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7d71f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
